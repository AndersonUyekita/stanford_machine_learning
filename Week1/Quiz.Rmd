---
title: "Quiz"
author: "Anderson Uyekita"
date: "29 de novembro de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

## Q1

A computer program is said to learn from experience E with respect to some task T and some performance measure P if its performance on T, as measured by P, improves with experience E. Suppose we feed a learning algorithm a lot of historical weather data, and have it learn to predict weather. What would be a reasonable choice for P?

The probability of it correctly predicting a future date's weather.

A computer program is said to learn from experience E with

respect to some task T and some performance measure P if its

performance on T, as measured by P, improves with experience E.

Suppose we feed a learning algorithm a lot of historical weather

data, and have it learn to predict weather. In this setting, what is T?

The weather prediction task.









## Q2

The amount of rain that falls in a day is usually measured in either millimeters (mm) or inches. Suppose you use a learning algorithm to predict how much rain will fall tomorrow. Would you treat this as a classification or a regression problem?

Regression

Suppose you are working on weather prediction, and you would

like to predict whether or not it will be raining at 5pm

tomorrow. You want to use a learning algorithm for this.

Would you treat this as a classification or a regression problem?

Classification

## Q3

Suppose you are working on stock market prediction. You would like to predict whether or not a certain company will declare bankruptcy within the next 7 days (by training on data of similar companies that had previously been at risk of bankruptcy). Would you treat this as a classification or a regression problem?

Classification

Suppose you are working on stock market prediction, Typically

tens of millions of shares of Microsoft stock are traded

(i.e., bought/sold) each day. You would like to predict the

number of Microsoft shares that will be traded tomorrow.

Would you treat this as a classification or a regression problem?

Regression

## Q4

Some of the problems below are best addressed using a supervised learning algorithm, and the others with an unsupervised learning algorithm. Which of the following would you apply supervised learning to? (Select all that apply.) In each case, assume some appropriate dataset is available for your algorithm to learn from.

In farming, given data on crop yields over the last 50 years, learn to predict next year's crop yields.

Given data on how 1000 medical patients respond to an experimental drug (such as effectiveness of the treatment, side effects, etc.), discover whether there are different categories or "types" of patients in terms of how they respond to the drug, and if so what these categories are.

Some of the problems below are best addressed using a supervised learning algorithm, and the others with an unsupervised learning algorithm. Which of the following would you apply supervised learning to? (Select all that apply.) In each case, assume some appropriate dataset is available for your algorithm to learn from.


Examine a large collection of emails that are known to be spam email, to discover if there are sub-types of spam mail.


Examine the statistics of two football teams, and predict which team will win tomorrow's match (given historical data of teams' wins/losses to learn from).




## Q5

Which of these is a reasonable definition of machine learning?

Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed.




# Linear Regression with One Variable

## Q1

Consider the problem of predicting how well a student does in her second year of college/university, given how well they did in their first year.

Specifically, let x be equal to the number of "A" grades (including A-. A and A+ grades) that a student receives in their first year of college (freshmen year). We would like to predict the value of y, which we define as the number of "A" grades they get in their second year (sophomore year).

Refer to the following training set of a small sample of different students' performances (note that this training set will also be referenced in other questions in this quiz). Here each row is one training example. Recall that in linear regression, our hypothesis is h_\theta(x) = \theta_0 + \theta_1x, and we use mm to denote the number of training examples.


m = 4

## Q2

```{r}
x <- c(1,2,4,0)
y <- c(0.5,1,2,0)

plot(x = x,y = y)


```

Pelo gráfico temos que $\theta_0$ é 0 (pois cruza o eixo em (0,0)) e $\theta_1$ é 0.5.

## Q3

$$h_0(x^{(i)}) = \theta_0 + \theta_1 x^{(i)}$$
Substituir os valores de $\theta_0$ = -2 e $\theta_1$ = 0.5.

$h_0(x^{(i)})$ = `r -2 + 0.5 * 6`

## Q4

Let ff be some function so that

f(\theta_0, \theta_1)f(θ 
0
	 ,θ 
1
	 ) outputs a number. For this problem,

ff is some arbitrary/unknown smooth function (not necessarily the

cost function of linear regression, so ff may have local optima).

Suppose we use gradient descent to try to minimize f(\theta_0, \theta_1)f(θ 
0
	 ,θ 
1
	 )

as a function of \theta_0θ 
0
	  and \theta_1θ 
1
	 . Which of the

following statements are true? (Check all that apply.)



If \theta_0θ 
0
	  and \theta_1θ 
1
	  are initialized at

the global minimum, then one iteration will not change their values.

If the first few iterations of gradient descent cause f(\theta_0, \theta_1)f(θ 
0
	 ,θ 
1
	 ) to

increase rather than decrease, then the most likely cause is that we have set the

learning rate \alphaα to too large a value.


## Q5

Suppose that for some linear regression problem (say, predicting housing prices as in the lecture), we

have some training set, and for our training set we managed to find some \theta_0θ 
0
	 , \theta_1θ 
1
	  such that J(\theta_0, \theta_1)=0J(θ 
0
	 ,θ 
1
	 )=0. Which

of the statements below must then be true? (Check all that apply.)


For these values of \theta_0θ 
0
	  and \theta_1θ 
1
	  that satisfy J(\theta_0, \theta_1) = 0J(θ 
0
	 ,θ 
1
	 )=0,

we have that h_\theta(x^{(i)}) = y^{(i)}h 
θ
	 (x 
(i)
 )=y 
(i)
  for every training example (x^{(i)}, y^{(i)})(x 
(i)
 ,y 
(i)
 )




